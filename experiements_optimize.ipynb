{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules import data_preprocessing as dp\n",
    "from src.modules import data_visualization as dv\n",
    "from src.modules import modeling as md\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the ticker symbol. Here we use 5 stocks \"AAPL MSFT AMD GOOG META\" as an example.\n",
    "tickers = ['aapl', 'amd', 'msft', 'meta', 'goog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tickers = ['amd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 19s 124ms/step - loss: 0.0060 - root_mean_squared_error: 0.0778\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 9s 140ms/step - loss: 9.4500e-04 - root_mean_squared_error: 0.0307\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 9s 139ms/step - loss: 7.9853e-04 - root_mean_squared_error: 0.0283\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 9s 148ms/step - loss: 7.2399e-04 - root_mean_squared_error: 0.0269\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 9s 153ms/step - loss: 0.0011 - root_mean_squared_error: 0.0332\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 9s 151ms/step - loss: 6.8097e-04 - root_mean_squared_error: 0.0261\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 9s 153ms/step - loss: 7.8978e-04 - root_mean_squared_error: 0.0281\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 11s 175ms/step - loss: 7.2491e-04 - root_mean_squared_error: 0.0269\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 11s 184ms/step - loss: 9.9414e-04 - root_mean_squared_error: 0.0315\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 10s 158ms/step - loss: 6.3159e-04 - root_mean_squared_error: 0.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thong.lam\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    # Download the data from Yahoo Finance\n",
    "    df = dp.download_data(ticker)\n",
    "\n",
    "    # clean the data\n",
    "    df = dp.clean_data(df)\n",
    "\n",
    "    # split the data into training set and testing set\n",
    "    train_df, test_df = dp.split_data(df)\n",
    "\n",
    "    # scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    train_scaled = scaler.fit_transform(train_df)\n",
    "    test_scaled = scaler.transform(test_df)\n",
    "\n",
    "    # create the training set and testing set\n",
    "    X_train, y_train = dp.create_dataset(train_scaled, 60)\n",
    "    X_test, y_test = dp.create_dataset(test_scaled, 60)\n",
    "\n",
    "    # reshape the data\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    # build the model\n",
    "    model = md.create_model(X_train=X_train, y_train=y_train)\n",
    "\n",
    "    # train the model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "    # save the model\n",
    "    model.save(f'models/{ticker}_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(503, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1954, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2517, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 70ms/step\n",
      "MSE 0.07070305463294783\n",
      "RMSE 0.26590046000890605\n"
     ]
    }
   ],
   "source": [
    "# Create the testing data set.\n",
    "# The testing data set contains the remaining 20% of the data but we have to\n",
    "# # include the last 60 days from the training data set to predict the first stock price of the test data set\n",
    "# scaled_data_test = scaled_dataset[num_training_points - window_size:, :]\n",
    "\n",
    "# # # Create the data sets x_test and y_test\n",
    "# X_test = []\n",
    "# y_test = dataset[num_training_points:, :]\n",
    "\n",
    "# for i in range(60, len(scaled_data_test)):\n",
    "#     X_test.append(scaled_data_test[i-window_size:i, 0])\n",
    "\n",
    "# # Convert the values into arrays for easier computation \n",
    "# X_test = np.array(X_test)\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "# scaled_data_test = scaled_data[num_training_points - window_size:, :]\n",
    "#X_test, y_test = convert_to_supervised(scaled_data_test, window_size)\n",
    "\n",
    "# predict the testing data\n",
    "predictions = model.predict(X_test)\n",
    "# predictions = scaler.inverse_transform(predictions)\n",
    "# y_test = scaler.inverse_transform(y_test)\n",
    " \n",
    "# evaluate result by mse and rmse metrics\n",
    "mse = np.mean(((predictions - y_test) ** 2))\n",
    "print(\"MSE\", mse)\n",
    "print(\"RMSE\", np.sqrt(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
